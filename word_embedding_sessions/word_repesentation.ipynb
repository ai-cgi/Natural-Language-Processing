{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import ConditionalFreqDist, FreqDist\n",
    "from itertools import groupby, chain\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing - Word representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words, what are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/representation.png\" width=50%/>\n",
    "\n",
    "| **Figure 1**: Word representations|\n",
    "|:-----------------:|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuters news corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10788\n",
      "Number of words: 31078\n",
      "Training and test size split\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ids\n",
       "test        3019\n",
       "training    7769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of documents: {}\".format(len(reuters.fileids())))\n",
    "print(\"Number of words: {}\".format(len(set([word.lower() \n",
    "                                            for doc in reuters.fileids() \n",
    "                                            for word in reuters.words(doc)]))))\n",
    "print(\"Training and test size split\")\n",
    "pd.DataFrame({'ids': map(lambda s: s.split(\"/\")[0], reuters.fileids())}).groupby(by='ids').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With different news categories: 90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['acq',\n",
       " 'alum',\n",
       " 'barley',\n",
       " 'bop',\n",
       " 'carcass',\n",
       " 'castor-oil',\n",
       " 'cocoa',\n",
       " 'coconut',\n",
       " 'coconut-oil',\n",
       " 'coffee']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"With different news categories: {}\".format(len(reuters.categories())))\n",
    "reuters.categories()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories are overlapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('castor-oil', 2),\n",
       " ('groundnut-oil', 2),\n",
       " ('lin-oil', 2),\n",
       " ('rye', 2),\n",
       " ('sun-meal', 2),\n",
       " ('copra-cake', 3),\n",
       " ('cotton-oil', 3),\n",
       " ('dfl', 3),\n",
       " ('nkr', 3),\n",
       " ('palladium', 3)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(cat, len(reuters.fileids(cat))) for cat in reuters.categories()],\n",
    "       key=itemgetter(1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  Thailand's trade deficit widened to 4.5\\n  billion baht in the first quarter of 1987 from 2.1 billion a\\n  year ago, the Business Economics Department said.\\n      It said Janunary/March imports rose to 65.1 billion baht\\n  from 58.7 billion. Thailand's improved business climate this\\n  year resulted in a 27 pct increase in imports of raw materials\\n  and semi-finished products.\\n      The country's oil import bill, however, fell 23 pct in the\\n  first quarter due to lower oil prices.\\n      The department said first quarter exports expanded to 60.6\\n  billion baht from 56.6 billion.\\n      Export growth was smaller than expected due to lower\\n  earnings from many key commodities including rice whose\\n  earnings declined 18 pct, maize 66 pct, sugar 45 pct, tin 26\\n  pct and canned pineapples seven pct.\\n      Products registering high export growth were jewellery up\\n  64 pct, clothing 57 pct and rubber 35 pct.\\n  \\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.raw('test/14832')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data structure that maps fileids to their respective categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test/14826', ['trade']),\n",
       " ('test/14828', ['grain']),\n",
       " ('test/14829', ['crude', 'nat-gas']),\n",
       " ('test/14832', ['corn', 'grain', 'rice', 'rubber', 'sugar', 'tin', 'trade']),\n",
       " ('test/14833', ['palm-oil', 'veg-oil']),\n",
       " ('test/14839', ['ship']),\n",
       " ('test/14840', ['coffee', 'lumber', 'palm-oil', 'rubber', 'veg-oil']),\n",
       " ('test/14841', ['grain', 'wheat']),\n",
       " ('test/14842', ['gold']),\n",
       " ('test/14843', ['acq'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_ids_cat = sorted([(fileid, cat) \n",
    "                       for cat in reuters.categories()\n",
    "                       for fileid in reuters.fileids(cat)], \n",
    "                      key=itemgetter(0))\n",
    "\n",
    "class_map = dict((k, list(map(itemgetter(1), v))) \n",
    "                 for k, v in groupby(sort_ids_cat, \n",
    "                                     key=itemgetter(0)))\n",
    "list(class_map.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bag of Words representation (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bahia</th>\n",
       "      <th>cocoa</th>\n",
       "      <th>review</th>\n",
       "      <th>showers</th>\n",
       "      <th>continued</th>\n",
       "      <th>throughout</th>\n",
       "      <th>the</th>\n",
       "      <th>week</th>\n",
       "      <th>in</th>\n",
       "      <th>zone</th>\n",
       "      <th>...</th>\n",
       "      <th>sticks</th>\n",
       "      <th>hostel</th>\n",
       "      <th>zincor</th>\n",
       "      <th>kms</th>\n",
       "      <th>johannesburg</th>\n",
       "      <th>quelled</th>\n",
       "      <th>minutes</th>\n",
       "      <th>police</th>\n",
       "      <th>arrived</th>\n",
       "      <th>fears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>training/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/1077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7071 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                bahia  cocoa  review  showers  continued  throughout   the  \\\n",
       "training/1        5.0    7.0     2.0      1.0        1.0         1.0  18.0   \n",
       "training/10       0.0    0.0     0.0      0.0        0.0         0.0  15.0   \n",
       "training/100      0.0    0.0     0.0      0.0        0.0         0.0   2.0   \n",
       "training/1000     0.0    0.0     0.0      0.0        0.0         0.0   8.0   \n",
       "training/10000    0.0    0.0     0.0      0.0        0.0         0.0   7.0   \n",
       "...               ...    ...     ...      ...        ...         ...   ...   \n",
       "training/1077     0.0    0.0     0.0      0.0        0.0         0.0   7.0   \n",
       "training/10770    0.0    0.0     0.0      0.0        0.0         0.0   7.0   \n",
       "training/10771    0.0    0.0     0.0      0.0        0.0         0.0  55.0   \n",
       "training/10773    0.0    0.0     0.0      0.0        0.0         0.0  21.0   \n",
       "training/10774    0.0    0.0     0.0      0.0        0.0         0.0  19.0   \n",
       "\n",
       "                week    in  zone  ...  sticks  hostel  zincor  kms  \\\n",
       "training/1       2.0   6.0   1.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/10      0.0   0.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/100     0.0   7.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/1000    0.0   0.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/10000   0.0   1.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "...              ...   ...   ...  ...     ...     ...     ...  ...   \n",
       "training/1077    0.0   2.0   0.0  ...     1.0     1.0     1.0  1.0   \n",
       "training/10770   0.0   2.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/10771   1.0  10.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/10773   0.0   6.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "training/10774   0.0   6.0   0.0  ...     0.0     0.0     0.0  0.0   \n",
       "\n",
       "                johannesburg  quelled  minutes  police  arrived  fears  \n",
       "training/1               0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "training/10              0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "training/100             0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "training/1000            0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "training/10000           0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "...                      ...      ...      ...     ...      ...    ...  \n",
       "training/1077            1.0      1.0      1.0     1.0      1.0    0.0  \n",
       "training/10770           0.0      0.0      0.0     0.0      0.0    1.0  \n",
       "training/10771           0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "training/10773           0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "training/10774           0.0      0.0      0.0     0.0      0.0    0.0  \n",
       "\n",
       "[500 rows x 7071 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_train_docs = 500\n",
    "max_test_docs = 100\n",
    "train_doc_ids = [doc_id for doc_id in reuters.fileids() \n",
    "                 if doc_id.startswith(\"training\")][:max_train_docs]\n",
    "#vocab_dist = FreqDist(word.lower()\n",
    "#                      for doc_id in train_doc_ids\n",
    "#                      for word in reuters.words(doc_id))\n",
    "#prog = re.compile('[a-z]+')\n",
    "#most_freq_words = [tpl[0] for tpl in vocab_dist.most_common() if prog.match(tpl[0])]\n",
    "\n",
    "def bow_transform(doc_ids):\n",
    "    cfd = ConditionalFreqDist((doc_id, word.lower())\n",
    "                              for doc_id in doc_ids\n",
    "                              for word in reuters.words(doc_id))\n",
    "    return pd.DataFrame(cfd).fillna(0).T\n",
    "\n",
    "bow = bow_transform(train_doc_ids)\n",
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and validation\n",
    "\n",
    "* How do we assign a class label to a document?\n",
    "   - Mean vector\n",
    "   - Supervised classification algorithm\n",
    "\n",
    "\n",
    "* How do we meassure the quality of our model?\n",
    "   - For every class\n",
    "   - For a set of classes\n",
    "   \n",
    "\n",
    "* What do we do with words we have never seen before?\n",
    "\n",
    "\n",
    "---\n",
    "## Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "* Intuition:\n",
    "> A high word frequency is not necessarily relevant (see last session). But if a word has a high frequency in one document relative to its frequency in all the other documents, we can assume that this word has a high relevance for this document.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "* Term frequency:\n",
    "> The frequency of a token normalized by the length of the document.\n",
    "\\\\[\n",
    "\\text{tf}(t, d) = \\frac{f_{t, d}}{N_{d}},\n",
    "\\\\]\n",
    "where \\\\(t\\\\) is a token in the document \\\\(d\\\\) and \\\\(N_{d}\\\\) is the number of tokens in the document.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "* Inverse document frequency:\n",
    "> A measure of how much information a word carries in the corpus.\n",
    "\\\\[\n",
    "\\text{idf}(t, D) = \\log \\left(\\frac{N_D}{|\\{d \\in D : t \\in d\\}|}\\right),\n",
    "\\\\]\n",
    "where \\\\(N_D\\\\) is the number of documents in the corpus and \\\\(|\\{d \\in D : t \\in d\\}|\\\\) is the number of documents in which the token \\\\(t\\\\) occures.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "* Term frequency - inverse document frequency:\n",
    "> \\\\[\n",
    "\\text{tf-idf}(t, d, D) = \\text{tf}(t, d) \\cdot \\text{idf}(t, D)\n",
    "\\\\]\n",
    "It is the BoW token frequency weighted by the occurence of the token in the corpus. As the frequency of the token across all documents increases the idf approaches 0, which controlls the influence of the tf.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "#### Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bahia</th>\n",
       "      <th>cocoa</th>\n",
       "      <th>review</th>\n",
       "      <th>showers</th>\n",
       "      <th>continued</th>\n",
       "      <th>throughout</th>\n",
       "      <th>the</th>\n",
       "      <th>week</th>\n",
       "      <th>in</th>\n",
       "      <th>zone</th>\n",
       "      <th>...</th>\n",
       "      <th>sticks</th>\n",
       "      <th>hostel</th>\n",
       "      <th>zincor</th>\n",
       "      <th>kms</th>\n",
       "      <th>johannesburg</th>\n",
       "      <th>quelled</th>\n",
       "      <th>minutes</th>\n",
       "      <th>police</th>\n",
       "      <th>arrived</th>\n",
       "      <th>fears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>training/1</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.00158</td>\n",
       "      <td>0.00158</td>\n",
       "      <td>0.00158</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.00158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.057915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.060870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/1077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7071 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bahia     cocoa   review  showers  continued  throughout  \\\n",
       "training/1      0.007899  0.011058  0.00316  0.00158    0.00158     0.00158   \n",
       "training/10     0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/100    0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/1000   0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/10000  0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "...                  ...       ...      ...      ...        ...         ...   \n",
       "training/1077   0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/10770  0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/10771  0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/10773  0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "training/10774  0.000000  0.000000  0.00000  0.00000    0.00000     0.00000   \n",
       "\n",
       "                     the      week        in     zone  ...    sticks  \\\n",
       "training/1      0.028436  0.003160  0.009479  0.00158  ...  0.000000   \n",
       "training/10     0.057915  0.000000  0.000000  0.00000  ...  0.000000   \n",
       "training/100    0.016807  0.000000  0.058824  0.00000  ...  0.000000   \n",
       "training/1000   0.051613  0.000000  0.000000  0.00000  ...  0.000000   \n",
       "training/10000  0.060870  0.000000  0.008696  0.00000  ...  0.000000   \n",
       "...                  ...       ...       ...      ...  ...       ...   \n",
       "training/1077   0.055556  0.000000  0.015873  0.00000  ...  0.007937   \n",
       "training/10770  0.067308  0.000000  0.019231  0.00000  ...  0.000000   \n",
       "training/10771  0.064103  0.001166  0.011655  0.00000  ...  0.000000   \n",
       "training/10773  0.066038  0.000000  0.018868  0.00000  ...  0.000000   \n",
       "training/10774  0.079832  0.000000  0.025210  0.00000  ...  0.000000   \n",
       "\n",
       "                  hostel    zincor       kms  johannesburg   quelled  \\\n",
       "training/1      0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10     0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/100    0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/1000   0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "...                  ...       ...       ...           ...       ...   \n",
       "training/1077   0.007937  0.007937  0.007937      0.007937  0.007937   \n",
       "training/10770  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10771  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10773  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10774  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "\n",
       "                 minutes    police   arrived     fears  \n",
       "training/1      0.000000  0.000000  0.000000  0.000000  \n",
       "training/10     0.000000  0.000000  0.000000  0.000000  \n",
       "training/100    0.000000  0.000000  0.000000  0.000000  \n",
       "training/1000   0.000000  0.000000  0.000000  0.000000  \n",
       "training/10000  0.000000  0.000000  0.000000  0.000000  \n",
       "...                  ...       ...       ...       ...  \n",
       "training/1077   0.007937  0.007937  0.007937  0.000000  \n",
       "training/10770  0.000000  0.000000  0.000000  0.009615  \n",
       "training/10771  0.000000  0.000000  0.000000  0.000000  \n",
       "training/10773  0.000000  0.000000  0.000000  0.000000  \n",
       "training/10774  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[500 rows x 7071 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tf_fn(doc):\n",
    "    N = doc.sum()\n",
    "    return doc.apply(lambda t: t/N)\n",
    "\n",
    "bow.apply(tf_fn, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bahia        6.214608\n",
       "cocoa        3.506558\n",
       "review       4.828314\n",
       "showers      5.521461\n",
       "continued    3.729701\n",
       "               ...   \n",
       "quelled      6.214608\n",
       "minutes      6.214608\n",
       "police       6.214608\n",
       "arrived      6.214608\n",
       "fears        6.214608\n",
       "Length: 7071, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_D = bow.shape[0] # Number of documents\n",
    "\n",
    "def idf_fn(term_col):\n",
    "    return np.log( N_D / sum(1 if t > 0 else 0 for t in term_col))\n",
    "\n",
    "bow.apply(idf_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bahia</th>\n",
       "      <th>cocoa</th>\n",
       "      <th>review</th>\n",
       "      <th>showers</th>\n",
       "      <th>continued</th>\n",
       "      <th>throughout</th>\n",
       "      <th>the</th>\n",
       "      <th>week</th>\n",
       "      <th>in</th>\n",
       "      <th>zone</th>\n",
       "      <th>...</th>\n",
       "      <th>sticks</th>\n",
       "      <th>hostel</th>\n",
       "      <th>zincor</th>\n",
       "      <th>kms</th>\n",
       "      <th>johannesburg</th>\n",
       "      <th>quelled</th>\n",
       "      <th>minutes</th>\n",
       "      <th>police</th>\n",
       "      <th>arrived</th>\n",
       "      <th>fears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>training/1</td>\n",
       "      <td>0.049089</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>0.015255</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/1077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training/10774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7071 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bahia     cocoa    review   showers  continued  throughout  \\\n",
       "training/1      0.049089  0.038777  0.015255  0.008723   0.005892    0.008723   \n",
       "training/10     0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/100    0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/1000   0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/10000  0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "...                  ...       ...       ...       ...        ...         ...   \n",
       "training/1077   0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/10770  0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/10771  0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/10773  0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "training/10774  0.000000  0.000000  0.000000  0.000000   0.000000    0.000000   \n",
       "\n",
       "                     the      week        in      zone  ...    sticks  \\\n",
       "training/1      0.010305  0.007091  0.004054  0.007275  ...  0.000000   \n",
       "training/10     0.020989  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "training/100    0.006091  0.000000  0.025159  0.000000  ...  0.000000   \n",
       "training/1000   0.018705  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "training/10000  0.022059  0.000000  0.003719  0.000000  ...  0.000000   \n",
       "...                  ...       ...       ...       ...  ...       ...   \n",
       "training/1077   0.020134  0.000000  0.006789  0.000000  ...  0.049322   \n",
       "training/10770  0.024393  0.000000  0.008225  0.000000  ...  0.000000   \n",
       "training/10771  0.023231  0.002616  0.004985  0.000000  ...  0.000000   \n",
       "training/10773  0.023932  0.000000  0.008070  0.000000  ...  0.000000   \n",
       "training/10774  0.028932  0.000000  0.010783  0.000000  ...  0.000000   \n",
       "\n",
       "                  hostel    zincor       kms  johannesburg   quelled  \\\n",
       "training/1      0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10     0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/100    0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/1000   0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "...                  ...       ...       ...           ...       ...   \n",
       "training/1077   0.049322  0.049322  0.049322      0.049322  0.049322   \n",
       "training/10770  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10771  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10773  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "training/10774  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "\n",
       "                 minutes    police   arrived     fears  \n",
       "training/1      0.000000  0.000000  0.000000  0.000000  \n",
       "training/10     0.000000  0.000000  0.000000  0.000000  \n",
       "training/100    0.000000  0.000000  0.000000  0.000000  \n",
       "training/1000   0.000000  0.000000  0.000000  0.000000  \n",
       "training/10000  0.000000  0.000000  0.000000  0.000000  \n",
       "...                  ...       ...       ...       ...  \n",
       "training/1077   0.049322  0.049322  0.049322  0.000000  \n",
       "training/10770  0.000000  0.000000  0.000000  0.059756  \n",
       "training/10771  0.000000  0.000000  0.000000  0.000000  \n",
       "training/10773  0.000000  0.000000  0.000000  0.000000  \n",
       "training/10774  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[500 rows x 7071 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = bow.apply(idf_fn)\n",
    "\n",
    "def tf_idf_fn(df):\n",
    "    tf = df.apply(tf_fn, axis=1)\n",
    "    return tf.apply(lambda d: d * idf.T, axis=1)\n",
    "\n",
    "tf_idf_fn(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Word embedding - word2vec\n",
    "\n",
    "### What is a word embedding?\n",
    "\n",
    "We want to represent words as vectors in a way, that the semantic relationships between words is encoded into their vector representation. \n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "<img src=\"../img/vec_space.png\" width=40%/>\n",
    "\n",
    "| **Figure 2**: Vector representation|\n",
    "|:-----------------:|\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "The most famous example of word embeddings was published by [Mikolov et.al 2013-A]\n",
    "> \"[...] This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King - Man + Woman” results in a vector very close to “Queen.”\"\n",
    "\n",
    "[Mikolov et.al 2013-A] [Linguistic Regularities in Continuous Space Word Representations - Tomas Mikolov, Wen-tau Yih, Geoffrey Zweig](https://www.aclweb.org/anthology/N13-1090)\n",
    "\n",
    "### The skip-gram model [Mikolov et.al 2013-B]\n",
    "\n",
    "The skip-gram model is a simple artificial neural network model with one hidden layer.\n",
    "The idea is that we train the network to do a predictive task, but we are not actually interessted in the network and its capabilties itself.\n",
    "We are interessted in the learnt weights of the network.\n",
    "These weights are the word embeddings we are looking for.\n",
    "\n",
    "The predictive task the network has to do is the following.\n",
    "Given a word in a sentence predict the likelihood for its surrounding words.\n",
    "E.g. given the word 'united' the likelihood that the next word is 'states' is higher than the likelihood that the next word is 'potatoes'.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "<img src=\"../img/training_data.png\" width=40%/>\n",
    "\n",
    "| **Figure 3**: [McCormick 2016]|\n",
    "|:-----------------:|\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "Again, we have to think about the representation of words.\n",
    "In this case we use a so called one-hot encoding, i.e. the dimensionality of the input vector is equal to the vocabulary size.\n",
    "The input vector is all zeros except for a single one representing the word.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "<img src=\"../img/skip_gram_net_arch.png\" width=40%/>\n",
    "\n",
    "| **Figure 4**: [McCormick 2016]|\n",
    "|:-----------------:|\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "The hidden layer uses no activation function, but the output layer uses the softmax function.\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "\\\\[\n",
    "f(x) = \\frac{e^{x^Tw}}{\\sum_{k=1}^K e^{x^Tw_k}}\n",
    "\\\\]\n",
    "\n",
    "\\\\[\\quad\\\\]\n",
    "\n",
    "The one-hot encoded word vector basically selects a single row from the hidden layer weight matrix.\n",
    "\n",
    "<img src=\"../img/matrix_mult_w_one_hot.png\" width=40%/>\n",
    "\n",
    "| **Figure 5**: [McCormick 2016]|\n",
    "|:-----------------:|\n",
    "\n",
    "This single row is fed into the output softmax layer together with the output weight vector.\n",
    "\n",
    "<img src=\"../img/output_weights_function.png\" width=40%/>\n",
    "\n",
    "| **Figure 6**: [McCormick 2016]|\n",
    "|:-----------------:|\n",
    "\n",
    "This model does not know anything about the order of words.\n",
    "For the model ('New', 'York') is the same as ('York', 'New')\n",
    "\n",
    "### Subsampling Frequent Words\n",
    "\n",
    "The word 'the' appears in the context of every word.\n",
    "Therefore it contains little information (see last session).\n",
    "Subsampling remove frequent words as training examples and as context words.\n",
    "\n",
    "### Negative Sampling\n",
    "\n",
    "When training a neural network with back propagation usually all the weight of the network are being updated.\n",
    "Our corpus likely has a vocabulary of more than 100k and possibly contains serveral million words, training becomes infeasible.\n",
    "But the training examples have a particular structure, namely they are one-hot encoded.\n",
    "Negative sampling exploits this structure and only updates the weights of the word which has the one and X additional words that are zero.\n",
    "\n",
    "[McCormick 2016] [Word2Vec Tutorial - The Skip-Gram Model - Chris McCormick](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "\n",
    "[Mikolov et.al 2013-B] [Distributed Representations of Words and Phrasesand their Compositionality - Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'],\n",
    "        ['He', 'laid', 'down', 'on', 'the', 'grass', '.']]\n",
    "\n",
    "corpus = [[word.lower() for word in sent] for sent in text]\n",
    "vocabulary = list(set(chain(*corpus)))\n",
    "\n",
    "win_size = 2\n",
    "\n",
    "def create_pairs_from_sent(sent, win_size):\n",
    "    rlt = []\n",
    "    for n in range(len(sent)):\n",
    "        context = sent[:n][-win_size:] + sent[n+1:][:win_size]\n",
    "        rlt.append(zip([sent[n]]*len(context), context))\n",
    "    return list(chain(*rlt))\n",
    "\n",
    "def one_hot_builder(vocabulary):\n",
    "    vocab_size = len(vocabulary)\n",
    "    def one_hot_encoder(word):\n",
    "        rlt = np.zeros(vocab_size)\n",
    "        rlt[vocabulary.index(word)] = 1\n",
    "        return rlt\n",
    "    def one_hot_decoder(word):\n",
    "        return vocabulary[np.argwhere(np.equal(word, 1))[0][0]]\n",
    "    return one_hot_encoder, one_hot_decoder\n",
    "\n",
    "one_hot_encoder, one_hot_decoder = one_hot_builder(vocabulary)\n",
    "\n",
    "train_pairs = list(chain(*map(lambda s: create_pairs_from_sent(s, win_size), \n",
    "                              corpus)))\n",
    "\n",
    "train_set = list(map(lambda tpl: (one_hot_encoder(tpl[0]), \n",
    "                                  one_hot_encoder(tpl[1])), \n",
    "                     train_pairs))\n",
    "train_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continued in Sesssion 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory Material\n",
    "\n",
    "https://www.kaggle.com/learn/overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
